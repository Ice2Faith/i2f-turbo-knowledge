# DevOps 开发运维一体化流程

- DevOps 其实就是（Develop and Operate）开发运维一体化
- 实现从代码的开发到直接运行变更的代码整个流程的自动化
- 也就是说，当代码提交之后，期间的编译、部署都进行自动化的运行
- 不需要运维的参与的这个流程，就叫做DevOps
- 要实现这样的目标，就需要借助一些自动化工具进行实现

## 主流实现

- Jekines流水线编排
- 也就是用Jekines实现DevOps各个流程的控制和协调
- 当然，现在也可以基于k8s集群，直接建立一个 KubeSphere 
- 里面可以方便的集成 Jekines 等组件，快速完成DevOps的集成

### 流水线过程
- 流水线的基础就是完成打包
- 一般也要完成部署更新
- 但不是说，必须要完成部署更新
- 所以，我们定义认为部署更新时可选的

- 传统部署到主机

```shell
触发流水线执行
从代码仓库拉取代码
编译打包
单元测试【可选】
代码质量检查【可选】
制品上传【可选】
部署更新【主机部署】【可选】
```

- 部署到虚拟化容器

```shell
触发流水线执行
从代码仓库拉取代码
编译打包
单元测试【可选】
代码质量检查【可选】
制品上传【可选】
镜像构建【虚拟化】【可选】
镜像推送【虚拟化】【可选】
部署更新【虚拟化】【可选】
```

## 参与组件
### 代码仓库：Gitlab/Gitee/Github
- 代码仓库用户保存和管理代码
- 同时，通过设置CI/CD自动触发事件
- 通过Webhooks通知监听的HTTP服务
- 这样，监听的服务就能通过事件知道代码发生了变更
- 从而触发一系列的操作
- 在DevOps中，就是起到触发Jekines流水线执行的目的

### 流水线编排：Jekines
- 用于管理和运行流水线
- 使得完成整个DevOps过程的编译和部署过程
- 可以被动的通过代码仓库的Webhook通知执行流水行
- 也可以通过UI也没指定执行流水线
- 也提供了参数化执行流水线的能力与插件化拓展的能力

### java编译打包工具：Maven/Gradle
- 用于编译打包java项目
- 生成制品jar或者war等

### web编译打包工具：nodejs/npm
- 用于编译打包web项目
- 生成dist这种类似的web资源文件

### 制品仓库：Nexus
- 用于保存Maven依赖或者打包的jar包，作为Maven私服使用
- 也可以用于保存npm依赖，作为npm私服使用

### 单元测试：JUnit
- 主要使用在java项目中进行单元测试
- 得到单元测试报告或者单元测试覆盖率
- 用于进行代码质量管控与审查

### 代码质量检查：SonarQube/FindBugs
- 主要是用于静态代码检查
- 检查代码中的编写不规范的地方
- 或者是代码中可能存在Bug的地方
- 讲这些异常点或者代码异味保留出来
- 也可以结合条件判断，要求异常数不超过配置的限制等等

### 镜像仓库：Horbor
- 主要用于保存容器的镜像
- 用于辅助构建私有的镜像
- 以及保存构建出来的私有镜像

### 镜像打包、推送：Docker
- 这个主要是使用一台安装了Docker的机器
- 完成从镜像仓库拉取基础镜像
- 根据Dockerfile构建出最终的镜像
- 最终将构建的镜像推送到镜像仓库

### 容器环境：K8S/Docker Compose
- 这个主要就是从镜像仓库拉取镜像
- 根据镜像和配置运行产生容器
- 管理容器的更新等

## 流水线步骤
- 标签说明
- 【通用】表示不管如何，都需要进行的环节
- 【可选】表示这个环节是可选的
- 【虚拟化】表示是使用镜像构建容器运行的虚拟化场景
- 【主机部署】表示传统的使用主机直接部署的场景

### 触发流水线执行【通用】
- 手动/被动触发Jekines流水线执行
- 手动点击执行Jekines执行流水线
- 被动接受代码仓库(Gitlab等)的Webhooks事件通知执行流水线
  - 在代码仓库的CI/CD中配置Webhooks通知地址
  - 当代码仓库发生Commit/Merge等操作时，可以使用HTTP通知监听的Webhook端点
  - 这样监听的端点就能够知道代码发生了变化
  - 从而能够触发一系列的操作
  - 这也是实现自动化的一部分

### 从代码仓库拉取代码【通用】

- 根据流水线的配置代码仓库
- 使用Git从Gitlab等代码仓库拉取代码
  - 比如，拉取指定的分支
  - 或者，监听的是合并分支的情况的话，可以拿到合并的目标分支
  - 这样，也可以拉去这个固定的分支的代码

### 编译打包【通用】

- 例如，java后端一般使用maven进行打包
  - 这时候，一般会使用自己的私服maven仓库
  - 一般是一个Nexus的maven私服
  - 这个主要是为了处理依赖其他的公司自身的依赖包的下载与保存
- 而web前端一般使用npm进行打包
  - 和上面一样，一般也都会有自己的前端组件库
  - 也就是需要一个npm私服
  - 一般也是一个Nexus的npm私服
  - 主要也是处理公司自己的前端组件的

### 单元测试【通用】【可选】

- 一般情况下，特别是后端，都会要求进行单元测试，计算单元测试的覆盖率
- 用以保证生产代码的质量
- 例如在java里面，一般是在【编译打包】过程中使用maven进行JUnit进行单元测试
  - 配合一些列的单元测试的maven插件，进行代码质量监控
  - 例如 jacoco插件，checkstyle插件，sonarlint插件，findbugs插件等
  - 这些插件如果运行不通过，将会阻断打包编译
  - 这样流水线就会执行失败
  - 返逼开发人员执行单元测试和代码质量控制

### 代码质量检查【通用】【可选】

- 同样，有两种方式
- 一种是使用外部的代码质量检查工具
  - 例如使用SonarQube进行代码质量检查
- 另一种是使用相关的代码质量检查插件
  - 像是在maven管理的java项目中
  - 使用jacoco,checkstyle,sonarlint,findbugs等编译插件
  - 进行代码质量检查，检查不通过将会编译失败
  - 导致流水线运行失败

### 制品上传【通用】

- 这个环节，就是将打包的制品、产物上传到私服仓库
- 这样能够在后续的环节能够访问得到
- 或者是实现归档管理
- 对于java项目来说，就是将打包得到的jar包等上传到maven私服Nexus仓库
- 对于web项目来说，可能没有这个环节
  - 但是，也有可能是将得到的dist目录压缩上传到固定的地方保存
  - 例如上传到FTP服务器，OSS对象存储中等

### 镜像构建【虚拟化】【可选】

- 镜像构建是针对使用虚拟化场景需求的
- 也就是使用docker运行，或者运行在k8s等平台中的时候
- 就需要进行镜像构建
- 如果，没有这种需求的时候，镜像构建则是不需要的
- 这个过程，也就是根据【编译打包】的结果
  - java项目的话一般结果就是一个jar包或者war包
  - web项目的话一般就是一个dist文件夹
- 然后根据每个项目，编写响应的Dockerfile文件用以构建镜像
  - java项目的话，也就是在Dockerfile中使用打包得到的jar包，基于jre的基础镜像，构建一个镜像
  - web项目的话，也就是在Dockerfile中使用打包得到的dist目录，基于nginx的基础镜像，构建一个镜像

### 镜像推送【虚拟化】【可选】

- 同样，这个是在虚拟化场景的需求下才需要的
- 如果没有这种需求，这个环节就是不需要的
- 这个环境，是将打包好的镜像，推送带镜像仓库的过程
- 一般情况下，公司会有自己的私服镜像仓库，一般是一个harbor仓库
- 就是要将构建好的镜像推送到私服仓库

### 制品分发【主机部署】【可选】

- 这个主要是针对传统项目直接部署到主机的情况
- 这个环节就是将打包得到的制品，分发传输到需要部署的主机上
- 比如，java项目的到的jar包通过SFTP传输到部署主机指定的目录中
- web项目就是将得到的dist目录压缩后通过SFTP传输到部署主机的指定目录中
- 这样，所有的需要部署的主机都得到了更新的制品

### 部署更新【主机部署】【可选】

- 这个是针对传统使用主机部署的场景的说明
- 经过【制品分发】之后，每个部署的主机都已经有了需要更新的制品内容
- 这个环节就是在主机上，实现部署更新应用
- 比如，对于java项目来说，就是使用SSH远程操作部署主机
  - 将制品jar包移动到应用目录覆盖jar文件，然后停止正在运行的这个进程，然后重新启动这个进程
  - 这样就实现了应用的更新
- 对于web应用来说，就是使用SSH远程操作部署主机
  - 将制品dist.zip解压到nginx的网页目录，覆盖文件
  - 根据实际情况，可能需要先删除已经存在的目录，避免旧文件污染
  - 因为nginx更新不需要重启，因此解压到指定目录就完成了更新

### 部署更新【虚拟化】【可选】

- 这里，虚拟化，主要是真的使用docker或者k8s平台
- 这种使用镜像进行构建的场景
- 这里分开进行说明
- 针对docker的场景
  - 一般是使用docker-compose进行部署
  - 所以，也就是在多台主机上，分别进行下线与重新上线应用
  - 也就是执行：docker compose down 与 docker compose up
  - 完成应用的更新，也有可能是预先准备一份shell脚本，完成这个操作
  - 实际只需要通过SSH远程操作执行这个过程即可完成更新
- 针对k8s的场景
  - 这个过程，其实就是将预先准备的k8s的yaml配置文件
  - 传输到k8s的master主机上
  - 然后，通过SSH提交这些k8s的yaml配置
  - 实现服务的更新
  - 当然，这个过程，也可能是执行一个脚本
  - 也可能，这些配置文件在项目搭建流水线的时候，就预先保存在master主机上
  - 也可能，这些配置文件就保存在代码仓库中
  - 通过SFTP上传再执行应用更新
